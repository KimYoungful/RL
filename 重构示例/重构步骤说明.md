# 重构步骤说明

本文档提供了具体的重构实施步骤和代码示例。

## 第一步：创建新的项目结构

### 1.1 创建目录结构

```bash
mkdir -p src/env
mkdir -p src/training
mkdir -p src/deployment
mkdir -p src/utils
mkdir -p src/scripts
mkdir -p config/env
mkdir -p config/training
mkdir -p tests
mkdir -p notebooks/exploration
```

### 1.2 创建基础配置文件

创建 `requirements.txt`：

```txt
gymnasium>=0.29.0
stable-baselines3>=2.0.0
numpy>=1.24.0
pygame>=2.5.0
pyyaml>=6.0
opencv-python>=4.8.0
mediapipe>=0.10.0
rtde>=1.5.0
ultralytics>=8.0.0
```

创建 `.gitignore`：

```gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/

# Jupyter Notebook
.ipynb_checkpoints

# 日志和模型
logs/
*.zip
*.pkl
*.pt
*.onnx

# 数据
data/
*.jpg
*.png
*.npz

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db
```

## 第二步：重构环境模块

### 2.1 创建环境配置类

文件：`src/env/config.py`（见重构建议文档）

### 2.2 创建基础环境类

文件：`src/env/base_env.py`（见重构建议文档）

### 2.3 创建带手臂约束的环境

文件：`src/env/arm_env.py`

```python
from typing import Optional, Tuple
import numpy as np
import random
from .base_env import BaseRobotEnv
from .config import EnvConfig

class ArmConstraintEnv(BaseRobotEnv):
    """带手臂约束的机器人环境"""
    
    def __init__(
        self,
        config: Optional[EnvConfig] = None,
        render_mode: Optional[str] = None
    ):
        super().__init__(config, render_mode)
        self.fixed_point: np.ndarray = np.zeros(2)
        self.dist_arm: float = 0.0
        self.distance_history: list = []
    
    def _get_observation_shape(self) -> int:
        """获取观测空间维度（增加手臂距离和固定点）"""
        return 2 + 2 + 2 + 1 + 1 + 1 + 2 + 1 + 1  # 增加dist_arm, fixed_point, stride_robot, stride_hand
    
    def _get_observation_high(self) -> np.ndarray:
        """获取观测空间上界"""
        base_high = super()._get_observation_high()
        return np.concatenate([
            base_high[:7],  # 基础观测
            np.array([
                self.config.distance_threshold_arm,
                self.config.grid_size * 2,
                self.config.grid_size,
                self.config.stride_robot_range[1],
                self.config.stride_hand_range[1]
            ])
        ])
    
    def _reset_positions(self):
        """重置位置（包括固定点）"""
        super()._reset_positions()
        # 随机生成固定点
        self.fixed_point = np.array([
            self.config.grid_size * random.uniform(0.2, 1.8),
            self.config.grid_size
        ])
        self.distance_history = []
    
    def _get_obs(self) -> np.ndarray:
        """获取观测（包含手臂距离）"""
        base_obs = super()._get_obs()
        
        # 计算到手臂的距离
        self.dist_arm = self._compute_arm_distance()
        
        return np.concatenate([
            base_obs[:7],  # 基础观测（去掉最后一个boundary，因为我们会重新计算）
            np.array([self.dist_arm]),
            self.fixed_point,
            np.array([self.stride_robot]),
            np.array([self.stride_hand])
        ]).astype(np.float32)
    
    def _compute_arm_distance(self) -> float:
        """计算机器人到手臂（手到固定点的线段）的距离"""
        return self._dist_point_to_segment(
            self.robot_position,
            self.hand_position,
            self.fixed_point
        )[0]
    
    def _dist_point_to_segment(
        self,
        P: np.ndarray,
        A: np.ndarray,
        B: np.ndarray,
        eps: float = 1e-12
    ) -> Tuple[float, np.ndarray, float, str]:
        """计算点到线段的距离"""
        P = np.asarray(P, dtype=float)
        A = np.asarray(A, dtype=float)
        B = np.asarray(B, dtype=float)
        
        v = B - A
        w = P - A
        vv = np.dot(v, v)
        
        if vv <= eps:
            C = A.copy()
            d = np.linalg.norm(P - A)
            t = 0.0
            case = 'endpoint_A'
        else:
            t = np.dot(w, v) / vv
            if t < 0.0:
                C = A
                d = np.linalg.norm(P - A)
                case = 'before_A'
            elif t > 1.0:
                C = B
                d = np.linalg.norm(P - B)
                case = 'after_B'
            else:
                C = A + t * v
                d = np.linalg.norm(P - C)
                case = 'on_segment'
        
        return float(d), C, float(t), case
    
    def _compute_reward(
        self,
        action: np.ndarray
    ) -> Tuple[float, bool, bool, Optional[str]]:
        """计算奖励（包含手臂约束）"""
        reward = 0.0
        terminated = False
        truncated = False
        done_reason = None
        
        # 计算手臂距离
        self.dist_arm = self._compute_arm_distance()
        self.distance_history.append(self.current_distance)
        
        # 手臂约束检查
        if self.dist_arm < self.config.distance_threshold_arm:
            reward += self.config.reward_arm
            terminated = True
            done_reason = "arm_constraint_violated"
            return reward, terminated, truncated, done_reason
        
        # 调用父类的奖励计算
        reward, terminated, truncated, done_reason = super()._compute_reward(action)
        
        return reward, terminated, truncated, done_reason
    
    def _get_info(self) -> dict:
        """获取信息（包含手臂距离）"""
        info = super()._get_info()
        info.update({
            'distance_arm': self.dist_arm,
            'fix_point': self.fixed_point.copy(),
            'distance_mean': np.mean(self.distance_history) if self.distance_history else 0.0
        })
        return info
```

## 第三步：创建训练模块

### 3.1 创建训练配置类

文件：`src/training/config.py`

```python
from dataclasses import dataclass, field
from typing import Dict, Any, Optional
import yaml

@dataclass
class TrainingConfig:
    """训练配置类"""
    algorithm: str = "SAC"  # SAC or PPO
    total_timesteps: int = 400000
    eval_freq: int = 10000
    n_eval_episodes: int = 10
    log_freq: int = 10000
    enable_debug_callback: bool = True
    model_kwargs: Dict[str, Any] = field(default_factory=dict)
    
    @classmethod
    def from_yaml(cls, yaml_path: str) -> 'TrainingConfig':
        """从YAML文件加载配置"""
        with open(yaml_path, 'r') as f:
            config_dict = yaml.safe_load(f)
        return cls(**config_dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """转换为字典"""
        return {
            field.name: getattr(self, field.name)
            for field in self.__dataclass_fields__.values()
        }
```

### 3.2 创建训练器

文件：`src/training/trainer.py`（见重构建议文档）

### 3.3 创建回调函数

文件：`src/training/callbacks.py`

```python
from collections import deque
from stable_baselines3.common.callbacks import BaseCallback
from typing import Optional

class DebugCallback(BaseCallback):
    """调试回调函数"""
    
    def __init__(
        self,
        env,
        render_freq: int = 10000,
        n_episodes: int = 1,
        log_freq: int = 10000,
        verbose: int = 1
    ):
        super().__init__(verbose)
        self.log_freq = log_freq
        self.termination_reasons = deque(maxlen=1000)
        self.distance_mean = deque(maxlen=1000)
        self.env_to_render = env
    
    def _on_step(self) -> bool:
        """每一步调用"""
        infos = self.locals.get('infos', None)
        dones = self.locals.get('dones', None)
        
        if infos is not None and dones is not None:
            for done, info in zip(dones, infos):
                if done and info is not None:
                    if 'done_reason' in info:
                        self.termination_reasons.append(info['done_reason'])
                    if 'distance_mean' in info:
                        self.distance_mean.append(info['distance_mean'])
        
        # 定期记录日志
        if self.num_timesteps % self.log_freq == 0 and self.verbose:
            self._log_metrics()
        
        return True
    
    def _log_metrics(self):
        """记录指标"""
        # 统计终止原因
        total = len(self.termination_reasons)
        if total > 0:
            count_out_of_bounds = sum(
                1 for r in self.termination_reasons
                if r == 'out_of_bounds'
            )
            ratio_out_of_bounds = count_out_of_bounds / total
        else:
            ratio_out_of_bounds = 0.0
        
        distance_mean = (
            sum(self.distance_mean) / len(self.distance_mean)
            if len(self.distance_mean) > 0 else 0.0
        )
        
        # 记录到TensorBoard
        self.logger.record("custom/termination_reason_ratio", ratio_out_of_bounds)
        self.logger.record("custom/distance_mean", distance_mean)
        self.logger.dump(step=self.num_timesteps)
```

## 第四步：创建配置文件

### 4.1 环境配置

文件：`config/env/arm_constraint.yaml`（见重构建议文档）

### 4.2 训练配置

文件：`config/training/sac.yaml`（见重构建议文档）

## 第五步：创建训练脚本

文件：`src/scripts/train.py`（见重构建议文档）

## 第六步：使用示例

### 6.1 训练模型

```bash
python src/scripts/train.py \
    --env-config config/env/arm_constraint.yaml \
    --training-config config/training/sac.yaml \
    --log-dir logs/training_run_1 \
    --seed 42
```

### 6.2 评估模型

```bash
python src/scripts/evaluate.py \
    --model-path logs/training_run_1/best_model/best_model.zip \
    --env-config config/env/arm_constraint.yaml \
    --n-episodes 100
```

## 注意事项

1. **逐步迁移**：不要一次性改变所有代码，逐步迁移更安全
2. **保持兼容**：在迁移过程中，保持与旧代码的兼容性
3. **测试验证**：每个步骤完成后，进行测试验证
4. **备份代码**：在开始重构前，备份原有代码

